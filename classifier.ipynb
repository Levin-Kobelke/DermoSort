{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from argparse import ArgumentParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv: pd.core.frame.DataFrame,\n",
    "        train: bool,\n",
    "        transform: Optional[callable] = None,\n",
    "    ):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.train_df = self.csv.sample(frac=0.8, random_state=200)\n",
    "        self.test_df = self.csv.drop(self.train_df.index)\n",
    "        if self.train:\n",
    "            self.csv = self.train_df\n",
    "        elif not self.train:\n",
    "            self.csv = self.test_df\n",
    "        self.targets = self.csv.target\n",
    "        self.imgs = self.csv[\"filepath\"]\n",
    "        self.samples = self.imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=image)\n",
    "            image = res[\"image\"].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "\n",
    "        data = torch.tensor(image).float()\n",
    "\n",
    "        return data, torch.tensor(self.csv.iloc[index].target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(image_size: int)-> Tuple[Callable, Callable]:\n",
    "    \"\"\"\n",
    "    Returns a composite of albumination transforms to apply to images. First one is strong for training and second one is weak for validation/training\n",
    "        Parameters:\n",
    "            image_size (int): The image size to crop to (always cropped to square)\n",
    "        Returns:\n",
    "            transforms_train, transforms_val (Callable): Composite of transforms\n",
    "\n",
    "    Augmentation strategy adapted from: Identifying Melanoma Images using EfficientNet Ensemble: Winning Solution to the SIIM-ISIC Melanoma Classification Challenge \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    transforms_train = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Transpose(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.RandomBrightness(limit=0.2, p=0.75),\n",
    "            albumentations.RandomContrast(limit=0.2, p=0.75),\n",
    "            albumentations.OneOf(\n",
    "                [\n",
    "                    albumentations.MotionBlur(blur_limit=5),\n",
    "                    albumentations.MedianBlur(blur_limit=5),\n",
    "                    albumentations.GaussianBlur(blur_limit=5),\n",
    "                    albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "                ],\n",
    "                p=0.7,\n",
    "            ),\n",
    "            albumentations.OneOf(\n",
    "                [\n",
    "                    albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "                    albumentations.GridDistortion(num_steps=5, distort_limit=1.0),\n",
    "                    albumentations.ElasticTransform(alpha=3),\n",
    "                ],\n",
    "                p=0.7,\n",
    "            ),\n",
    "            albumentations.CLAHE(clip_limit=4.0, p=0.7),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5\n",
    "            ),\n",
    "            albumentations.ShiftScaleRotate(\n",
    "                shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85\n",
    "            ),\n",
    "            albumentations.Resize(image_size, image_size),\n",
    "            albumentations.Cutout(\n",
    "                max_h_size=int(image_size * 0.375),\n",
    "                max_w_size=int(image_size * 0.375),\n",
    "                num_holes=1,\n",
    "                p=0.7,\n",
    "            ),\n",
    "            albumentations.Normalize(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    transforms_val = albumentations.Compose(\n",
    "        [albumentations.Resize(image_size, image_size), albumentations.Normalize()]\n",
    "    )\n",
    "\n",
    "    return transforms_train, transforms_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dataset(train: bool) -> object:\n",
    "    \"\"\"\n",
    "    Returns instance of dataset\n",
    "        Parameters:\n",
    "            train (bool): true for trainloader, dalse for val/testloader\n",
    "        Returns:\n",
    "            instance of dataset\n",
    "    \"\"\"\n",
    "\n",
    "    root = os.getcwd()\n",
    "\n",
    "\n",
    "    datasets = [\"d7p\",\"ham10000\",\"ph2\",\"isic_2020\"]\n",
    "    dataframes = []\n",
    "    for dataset in datasets:\n",
    "        csv_file = f\"{root}/{dataset}_binaryclass\"\n",
    "        df_train = pd.read_csv(csv_file)\n",
    "        datafolder = dataset\n",
    "        dataroot = \"/home/l049e/Data/\"\n",
    "        data_dir = os.path.join(dataroot+datafolder)\n",
    "        df_train[\"filepath\"] = data_dir + \"/\" + df_train[\"filepath\"]\n",
    "        col_to_keep = [\"filepath\", \"target\"]\n",
    "        df_train = df_train[col_to_keep]\n",
    "        dataframes.append(df_train)\n",
    "    \n",
    "    df_train = pd.concat(dataframes)\n",
    "\n",
    "    transforms_train, transforms_val = get_transforms(512)\n",
    "    if train:\n",
    "        transforms = transforms_train\n",
    "    else:\n",
    "        transforms = transforms_val\n",
    "    pass_kwargs = {\"csv\": df_train, \"train\": train, \"transform\": transforms}\n",
    "    return BasicDataset(**pass_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "\n",
    "class EfficientNetb4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetb4, self).__init__()\n",
    "        num_classes = 2\n",
    "        self.model = timm.create_model(\n",
    "            \"efficientnet_b4\",\n",
    "            pretrained=True,\n",
    "            num_classes=num_classes,\n",
    "            drop_rate=0,\n",
    "        )\n",
    "        self.model.reset_classifier(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickletools import optimize\n",
    "from sched import scheduler\n",
    "from zmq import device\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "def prepare(rank, world_size, batch_size=16, pin_memory=False, num_workers=0):\n",
    "    dataset = get_dataset(train=True)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers, drop_last=False, shuffle=False, sampler=sampler)\n",
    "    \n",
    "    return dataloader\n",
    "def main(rank, world_size):\n",
    "    # setup the process groups\n",
    "    setup(rank, world_size)\n",
    "    # prepare the dataloader\n",
    "    dataloader = prepare(rank, world_size)\n",
    "\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "\n",
    "    model = EfficientNetb4()\n",
    "    model = model.to(rank)\n",
    "    model = DDP(model, device_ids=[rank], output_device=rank)\n",
    "\n",
    "    num_epochs = 30\n",
    "    optimizer = optim.Adam(model.parameters(),lr = 0.00003 )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=10,T_mult=10)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        dist.barrier()\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            outputs = model(*batch)\n",
    "            labels = batch[\"target\"]\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "    cleanup()\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3622112/900647867.py:17: DtypeWarning: Columns (16,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(csv_file)\n",
      "/home/l049e/miniconda3/envs/derma/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/l049e/miniconda3/envs/derma/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/l049e/miniconda3/envs/derma/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1765: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/home/l049e/miniconda3/envs/derma/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:50: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65640"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we load a DDP model checkpoint to a non-DDP model\n",
    "model_dict = OrderedDict()\n",
    "pattern = re.compile('module.')\n",
    "for k,v in state_dict.items():\n",
    "    if re.search(\"module\", k):\n",
    "        model_dict[re.sub(pattern, '', k)] = v\n",
    "    else:\n",
    "        model_dict = state_dict\n",
    "model.load_state_dict(model_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('derma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "447890eb73e44667338d4e54bea3cb35923224c245a138395214c22a64450617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
